{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832be2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\anaconda3\\envs\\pybuild\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import glob2\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os.path\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pytz\n",
    "import pandas_gbq\n",
    "import mysql.connector as mysql\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import datetime\n",
    "from datetime import time\n",
    "from email.utils import parsedate_to_datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "import xmltodict\n",
    "from ast import literal_eval\n",
    "from collections.abc import MutableMapping\n",
    "import shlex\n",
    "import subprocess\n",
    "from woocommerce import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d0ee86-f9a9-46e8-937d-1c1b0680c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"status.log\", \n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    filemode='w') \n",
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb799b8-779e-4bf7-90ec-049ee96b0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime('today').strftime(\"%m-%d-%Y\")\n",
    "excelfilename = date +\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5a2543-9e0a-4003-bae7-fdeffca3677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfolders = '/cloudwork/portfolio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da53427-2ca2-419b-a0e0-40e3bcc9aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(pathfolders + 'projectb/keys.json')\n",
    "data = json.load(f)\n",
    "keyw = data['tokenw']['keyw']\n",
    "secretw = data['tokenw']['secretw']\n",
    "linkw = data['tokenw']['linkw']\n",
    "linkreq = data['tokenw']['linkreq']\n",
    "keye = data['tokene']['keye']\n",
    "secrete = data['tokene']['secrete']\n",
    "linke = data['tokene']['url']\n",
    "user_agente = data['tokene']['user_agent']\n",
    "keyo = data['tokeno']['keyo']\n",
    "secreto = data['tokeno']['secreto']\n",
    "linko = data['tokeno']['linko']\n",
    "tokent = data['tokent']['keyt']\n",
    "linkt = data['tokent']['linkt']\n",
    "tokenv = data['tokenv']['keyv']\n",
    "linkv = data['tokenv']['linkv']\n",
    "tokenss = data['tokenss']['keyss']\n",
    "linkss = data['tokenss']['linkss']\n",
    "tokennr = data['tokennr']['keynr']\n",
    "linknr = data['tokennr']['linknr']\n",
    "tokens5 = data['tokens5']['keys5']\n",
    "tokenaf = data['tokenaf']['keyaf']\n",
    "tokenbx = data['tokenbx']['keybx']\n",
    "tokenlt = data['tokenlt']['keylt']\n",
    "keywa = data['tokenwa']['keywa']\n",
    "secretwa = data['tokenwa']['secretwa']\n",
    "linkw = data['tokenwa']['linkw']\n",
    "linkgra = data['tokenwa']['linkgra']\n",
    "audience = data['tokenwa']['audience']\n",
    "localdb = data['localdatabasepass']['keydb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460ecbfd-d1d2-4306-8410-72e86cb1750f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Current_Date = datetime.datetime.today()\n",
    "weekago = datetime.datetime.today() + datetime.timedelta(days=-7)\n",
    "filterbydate = datetime.datetime.today() + datetime.timedelta(days=-1)\n",
    "weekago = weekago.replace(hour=0, minute=0, second=0)\n",
    "filterbydate = filterbydate.replace(hour=23, minute=59, second=59)\n",
    "Current_Date = Current_Date.replace(hour=23, minute=59, second=59)\n",
    "Current_Date = str(Current_Date)\n",
    "weekago = str(weekago)\n",
    "filterbydate = str(filterbydate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5a8c20-4288-4e86-90b8-246b78e338d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salesheader = ['sku','qty', 'site']\n",
    "dscosales = pd.DataFrame()\n",
    "source13sold = pd.DataFrame()\n",
    "source3sold = pd.DataFrame()\n",
    "source4sold = pd.DataFrame()\n",
    "source5sold = pd.DataFrame()\n",
    "source6sold = pd.DataFrame()\n",
    "source2reqsold = pd.DataFrame()\n",
    "source1sold = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40be097-8175-494d-9e6f-d6a9250cff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d574ffe-5273-479c-a003-6d3b2500fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "source1path = data['paths']['source1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1795834-ff89-48ed-b0c8-e4c97a8dbb35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenreq(source1path):\n",
    "    clientCredentialEndpoint = source1path\n",
    "    userpass =  keyw + ':' + secretw\n",
    "    encoded_u = base64.b64encode(userpass.encode()).decode()\n",
    "    queryParams ={\n",
    "        'grant_type':'client_credentials'\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Basic %s\" % encoded_u,\n",
    "        \"WM_QOS.CORRELATION_ID\": \"2e7bd8e1-309f-42ab-94bd-3bf33c101208\",\n",
    "        \"WM_SVC.NAME\": \"Service Name\",\n",
    "        \"accept\": \"application/xml\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    response = requests.post(\n",
    "        clientCredentialEndpoint,\n",
    "        data=queryParams,\n",
    "        headers=headers\n",
    "    )\n",
    "    data = xmltodict.parse(response.content)\n",
    "    accesstoken = list(data.values())[0]\n",
    "    source1token = accesstoken['accessToken']\n",
    "    return source1token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09239a32-0015-410f-8795-cf817df8bb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def source1tokenapi(token):\n",
    "    source1date = datetime.datetime.today().date()+ datetime.timedelta(days=-7)\n",
    "    source1date = str(source1date)\n",
    "    clientCredentialEndpoint = f\"{linkreq}{source1date}\"\n",
    "    queryParams ={\n",
    "        'grant_type':'client_credentials'\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"WM_SEC.ACCESS_TOKEN\": token,\n",
    "        \"WM_QOS.CORRELATION_ID\": \"2e7bd8e1-309f-42ab-94bd-3bf33c101208\",\n",
    "        \"WM_SVC.NAME\": \"Service Name\",\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(\n",
    "        clientCredentialEndpoint,\n",
    "        data=queryParams,\n",
    "        headers=headers\n",
    "    )\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43db75f3-dec3-4647-8be1-cf14b7c2dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3948357177.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source1sold = source1sold.append(source1sold, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if source1tokenapi(tokenreq(source1path)).ok:\n",
    "    try:\n",
    "        source1response = json.loads(source1tokenapi(tokenreq(source1path)).text)\n",
    "        source1aresponse = pd.json_normalize(source1response)\n",
    "        source1orders = source1aresponse['list.elements.order'].iloc[0]\n",
    "        source1orders = pd.json_normalize(source1orders) \n",
    "        FIELDS = ['orderLines.orderLine']\n",
    "        dt = source1orders[FIELDS]\n",
    "        dt = dt.explode('orderLines.orderLine')\n",
    "        df_final = (pd.DataFrame(dt['orderLines.orderLine'].apply(pd.Series)))\n",
    "        df3 = pd.concat([df_final.item.apply(pd.Series), df_final.drop('item', axis=1)], axis=1)\n",
    "        df4 = pd.concat([df3.orderLineQuantity.apply(pd.Series), df3.drop('orderLineQuantity', axis=1)], axis=1)\n",
    "        source1read = df4.rename({'amount': 'qty'}, axis=1)\n",
    "        source1read['site'] = 'source1'\n",
    "        source1read = source1read[['sku', 'qty', 'site']]\n",
    "        source1sold = pd.DataFrame(source1read, columns=salesheader)\n",
    "        source1sold = source1sold.append(source1sold, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError, ValueError):\n",
    "        print(\"There is no source1 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6097db72-45f9-4fad-8274-39e1083bc5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SOURCE1 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "763ebaad-9b11-4a88-bb40-9f7ef39d598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1bbfdd1-e3a9-464f-8572-acbf34840c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def siteapi():\n",
    "    wcApi = API(\n",
    "        url=linke,\n",
    "        consumer_key=keye,\n",
    "        consumer_secret=secrete,\n",
    "        wp_api=True,\n",
    "        version=\"wc/v3\",\n",
    "        user_agent= user_agente\n",
    "    )\n",
    "    orders = wcApi.get(\"orders\", params={\"per_page\": 20}).json()\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d1cb6e-a4ed-48d1-bf72-463108c7bc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source2 = pd.json_normalize(siteapi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e01372-1c99-4d7a-bdd7-a2208731a47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3144462034.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source2reqsold = source2reqsold.append(source2req, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if not source2.empty :\n",
    "    try:\n",
    "        source2 = source2.loc[source2['status'] == 'completed']\n",
    "        source2['date_created'] = pd.to_datetime(source2['date_created'], errors='coerce')\n",
    "        source2['datetofilter'] = source2['date_created'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        source2 = source2[(source2['datetofilter'] > weekago) & (source2['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['line_items']\n",
    "        dt = source2[FIELDS]\n",
    "        dt = dt.explode('line_items')\n",
    "        source2final = (pd.DataFrame(dt['line_items'].apply(pd.Series)))\n",
    "        source2req = source2final[['sku', 'quantity']]\n",
    "        source2req = source2req.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source2req['site'] = 'source2'\n",
    "        source2req = pd.DataFrame(source2req, columns=salesheader)\n",
    "        source2reqsold = source2reqsold.append(source2req, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "         print(\"There is no source2 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b00f87-072d-4f21-ae5a-9e6e19ae230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE2 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e09737-681c-4b3e-9e24-cc8adcd1a298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SOURCE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "657e44fd-f1de-40f0-b32b-50ea82f38445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3451569273.py:20: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  df = pd.DataFrame(data,columns = ['sku','quantity', 'CreateDate', 'postatus'], dtype = float)\n",
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3451569273.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source3sold = source3sold.append(source3stock, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "source3date = datetime.datetime.today().date()+ datetime.timedelta(days=+1)\n",
    "source3date = str(source3date)\n",
    "headers = {'Content-Type': 'application/xml', 'Connection':'keep-alive', 'Accept':'application/xml'}\n",
    "source3req = requests.get(f\"{linko}{source3date}\", auth=(keyo, secreto), headers=headers)\n",
    "\n",
    "if source3req.ok:\n",
    "    try:\n",
    "        xmlread = source3req.content\n",
    "        soup = BeautifulSoup(xmlread,'xml')\n",
    "        sku = soup.find_all('partnerSKU')\n",
    "        quantity = soup.find_all('quantity')\n",
    "        salesChannelOrderNumber = soup.find_all('salesChannelOrderNumber')\n",
    "        pubdate = soup.find_all('sofsCreatedDate')\n",
    "        postatus = soup.find_all('status')\n",
    "        data = []\n",
    "        for i in range(0,len(pubdate)):\n",
    "            rows = [sku[i].get_text(),quantity[i].get_text(),\n",
    "                   pubdate[i].get_text(), postatus[i].get_text()]\n",
    "            data.append(rows)\n",
    "        df = pd.DataFrame(data,columns = ['sku','quantity', 'CreateDate', 'postatus'], dtype = float)\n",
    "        df = df.loc[df['postatus'] != 'CANCELLED']\n",
    "        df['CreateDate'] = pd.to_datetime(df['CreateDate'], errors='coerce')\n",
    "        df['datetofilter'] = df['CreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df['datetofilter'] = df['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df = df[(df['datetofilter'] > weekago) & (df['datetofilter'] < filterbydate)]\n",
    "        source3read = df[['sku', 'quantity']]\n",
    "        source3read = source3read.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source3read['site'] = 'source3'\n",
    "        source3stock = pd.DataFrame(source3read, columns=salesheader)\n",
    "        source3sold = source3sold.append(source3stock, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source3 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1141b51-d77a-404d-8455-5763d4f1e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE3 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d65eff94-b370-4b3f-9e8c-30a73c6dbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7ab9902-0bea-40a0-8a8a-1373b1e9f4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3177302152.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source4sold = source4sold.append(source4sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_uri = f'{linkt}'\n",
    "headers = {'Authorization': tokent}\n",
    "source4response = requests.get(f'{base_uri}', headers=headers)\n",
    "source4response.json()\n",
    "if source4response.ok:\n",
    "    try:\n",
    "        orders = json.loads(source4response.text)\n",
    "        source4orders = pd.json_normalize(orders, 'orders')\n",
    "    except :\n",
    "        print(\"NO\")\n",
    "if source4response.text:\n",
    "    try:\n",
    "        source4orders = source4orders.loc[source4orders['order_state'] != 'CANCELED']\n",
    "        source4orders['created_date'] = pd.to_datetime(source4orders['created_date'], errors='coerce')\n",
    "        source4orders['datetofilter'] = source4orders['created_date'].dt.tz_convert('US/Eastern')\n",
    "        source4orders['datetofilter'] = source4orders['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        source4orders = source4orders[(source4orders['datetofilter'] > weekago) & (source4orders['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['order_lines']\n",
    "        dt = source4orders[FIELDS]\n",
    "        dt = dt.explode('order_lines')\n",
    "        df_final = (pd.DataFrame(dt['order_lines'].apply(pd.Series)))\n",
    "        source4read = df_final[['offer_sku', 'quantity']]\n",
    "        source4read = source4read.rename({'offer_sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source4read['site'] = 'source4'\n",
    "        source4sales = pd.DataFrame(source4read, columns=salesheader)\n",
    "        source4sold = source4sold.append(source4sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source4 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b617be39-7af1-47ff-b5ad-c2f5dbd6e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE4 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77b9dc8d-9d47-4026-ab39-8a4314dabc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SOURCE5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43e26e64-eeb8-4d9f-b549-db30dc8c63d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3431676971.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source5sold = source5sold.append(source5sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_uri = f'{linkv}'\n",
    "headers = {'Authorization': tokenv}\n",
    "source5response = requests.get(f'{base_uri}', headers=headers)\n",
    "if source5response.ok:\n",
    "    try:\n",
    "        orders = json.loads(source5response.text)\n",
    "        source5orders = pd.json_normalize(orders, 'orders')\n",
    "    except :\n",
    "        print(\"NO\")\n",
    "if source5response.text:\n",
    "    try:\n",
    "        source5orders = source5orders.loc[source5orders['order_state'] != 'CANCELED']\n",
    "        source5orders['created_date'] = pd.to_datetime(source5orders['created_date'], errors='coerce')\n",
    "        source5orders['datetofilter'] = source5orders['created_date'].dt.tz_convert('US/Eastern')\n",
    "        source5orders['datetofilter'] = source5orders['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        source5orders = source5orders[(source5orders['datetofilter'] > weekago) & (source5orders['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['order_lines']\n",
    "        dt = source5orders[FIELDS]\n",
    "        dt = dt.explode('order_lines')\n",
    "        df_final = (pd.DataFrame(dt['order_lines'].apply(pd.Series)))\n",
    "        source5read = df_final[['offer_sku', 'quantity']]\n",
    "        source5read = source5read.rename({'offer_sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source5read['site'] = 'source5'\n",
    "        source5sales = pd.DataFrame(source5read, columns=salesheader)\n",
    "        source5sold = source5sold.append(source5sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source5shop Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ffa7c44-21d0-41f8-a82c-f671b727d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE5 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b494a22-1bc6-4eee-a33d-86b48b372a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "570ac4ec-01ba-45cc-b0ac-208cad19519d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3734167130.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source6sold = source6sold.append(source6sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_uri = f'{linkss}'\n",
    "headers = {'Authorization': tokenss}\n",
    "response = requests.get(f'{base_uri}', headers=headers)\n",
    "response.json()\n",
    "if response.text:\n",
    "    try:\n",
    "        orders = json.loads(response.text)\n",
    "        source6k = pd.json_normalize(orders, 'orders')\n",
    "    except :\n",
    "        print(\"NO\")\n",
    "if response.text:\n",
    "    try:\n",
    "        source6k = source6k.loc[source6k['order_state'] != 'CANCELED']\n",
    "        source6k['created_date'] = pd.to_datetime(source6k['created_date'], errors='coerce')\n",
    "        source6k['datetofilter'] = source6k['created_date'].dt.tz_convert('US/Eastern')\n",
    "        source6k['datetofilter'] = source6k['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        source6k = source6k[(source6k['datetofilter'] > weekago) & (source6k['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['order_lines']\n",
    "        dt = source6k[FIELDS]\n",
    "        dt = dt.explode('order_lines')\n",
    "        df_final = (pd.DataFrame(dt['order_lines'].apply(pd.Series)))\n",
    "        source6read = df_final[['offer_sku', 'quantity']]\n",
    "        source6read = source6read.rename({'offer_sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source6read['site'] = 'source6'\n",
    "        source6sales = pd.DataFrame(source6read, columns=salesheader)\n",
    "        source6sold = source6sold.append(source6sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source6 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "707405e1-7918-42db-bab0-7f7fc2228e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE6 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4a31768-ecf0-4933-a047-67c63d82e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc61aa1b-6957-4ec3-8928-518783c0f51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\4026081501.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dscosales = dscosales.append(source7sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = f'{linknr}'\n",
    "\n",
    "params = {'ordersCreatedSince': {weekago}, 'until': {Current_Date} }\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + tokennr, \"Content-Type\":\"application/json\", \"Accept\":\"application/json\" }\n",
    "auth_response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "orders = json.loads(auth_response.text)\n",
    "df = pd.json_normalize(orders, 'orders')\n",
    "if orders:\n",
    "    try:\n",
    "        df['dscoCreateDate'] = pd.to_datetime(df['dscoCreateDate'], errors='coerce')\n",
    "        df['datetofilter'] = df['dscoCreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df['datetofilter'] = df['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df = df[(df['datetofilter'] > weekago) & (df['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['lineItems']\n",
    "        dt = df[FIELDS]\n",
    "        dt = dt.explode('lineItems')\n",
    "        df_final = (pd.DataFrame(dt['lineItems'].apply(pd.Series)))\n",
    "        dscoread = df_final[['sku', 'quantity']]\n",
    "        dscoread = dscoread.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        dscoread['site'] = 'source7'\n",
    "        source7sales = pd.DataFrame(dscoread, columns=salesheader)\n",
    "        dscosales = dscosales.append(source7sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source7 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d1f84eb-0e32-488c-b674-8cf9fbdeb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE7 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8d36805-a4d2-4674-9ddc-580e374438af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aefa2f8e-77e3-494e-a8df-624946e5c3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\3601749234.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dscosales = dscosales.append(source8sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = f'{linknr}'\n",
    "params = {'ordersCreatedSince': {weekago}, 'until': {Current_Date} }\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + tokens5, \"Content-Type\":\"application/json\", \"Accept\":\"application/json\" }\n",
    "auth_response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "orders = json.loads(auth_response.text)\n",
    "df3 = pd.json_normalize(orders, 'orders')\n",
    "if orders:\n",
    "    try:\n",
    "        df3['dscoCreateDate'] = pd.to_datetime(df3['dscoCreateDate'], errors='coerce')\n",
    "        df3['datetofilter'] = df3['dscoCreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df3['datetofilter'] = df3['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df3 = df3[(df3['datetofilter'] > weekago) & (df3['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['lineItems']\n",
    "        dt = df3[FIELDS]\n",
    "        dt = dt.explode('lineItems')\n",
    "        df_final = (pd.DataFrame(dt['lineItems'].apply(pd.Series)))\n",
    "        source8 = df_final[['sku', 'quantity']]\n",
    "        source8 = source8.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source8['site'] = 'source8'\n",
    "        source8sales = pd.DataFrame(source8, columns=salesheader)\n",
    "        dscosales = dscosales.append(source8sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source8 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed79c1bc-f6d9-4979-99ef-8690ddf3531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE8 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873a6858-7d19-466c-bda6-94d1c2d3e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b20b5ae-f51e-4ef8-a224-b81c3a7d2784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\1409209896.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dscosales = dscosales.append(source9sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = f'{linknr}'\n",
    "\n",
    "params = {'ordersCreatedSince': {weekago}, 'until': {Current_Date} }\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + tokenaf, \"Content-Type\":\"application/json\", \"Accept\":\"application/json\" }\n",
    "auth_response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "orders = json.loads(auth_response.text)\n",
    "df3 = pd.json_normalize(orders, 'orders')\n",
    "if orders:\n",
    "    try:\n",
    "        df3['dscoCreateDate'] = pd.to_datetime(df3['dscoCreateDate'], errors='coerce')\n",
    "        df3['datetofilter'] = df3['dscoCreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df3['datetofilter'] = df3['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df3 = df3[(df3['datetofilter'] > weekago) & (df3['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['lineItems']\n",
    "        dt = df3[FIELDS]\n",
    "        dt = dt.explode('lineItems')\n",
    "        df_final = (pd.DataFrame(dt['lineItems'].apply(pd.Series)))\n",
    "        asource9 = df_final[['sku', 'quantity']]\n",
    "        asource9 = asource9.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        asource9['site'] = 'source9'\n",
    "        source9sales = pd.DataFrame(asource9, columns=salesheader)\n",
    "        dscosales = dscosales.append(source9sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print(\"There is no source9 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e064b6c-ea5d-4ac1-bcdb-9298c6d06866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE9 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "910684c6-d9dc-49e3-8f4c-f98eecb9f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cacca2d-124a-41fd-b32e-eb79b380350e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\1952262977.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dscosales = dscosales.append(source10sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = f'{linknr}'\n",
    "params = {'ordersCreatedSince': {weekago}, 'until': {Current_Date} }\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + tokenbx, \"Content-Type\":\"application/json\", \"Accept\":\"application/json\" }\n",
    "auth_response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "orders = json.loads(auth_response.text)\n",
    "df3 = pd.json_normalize(orders, 'orders')\n",
    "if orders:\n",
    "    try:\n",
    "        df3['dscoCreateDate'] = pd.to_datetime(df3['dscoCreateDate'], errors='coerce')\n",
    "        df3['datetofilter'] = df3['dscoCreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df3['datetofilter'] = df3['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df3 = df3[(df3['datetofilter'] > weekago) & (df3['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['lineItems']\n",
    "        dt = df3[FIELDS]\n",
    "        dt = dt.explode('lineItems')\n",
    "        df_final = (pd.DataFrame(dt['lineItems'].apply(pd.Series)))\n",
    "        brandx = df_final[['sku', 'quantity']]\n",
    "        brandx = brandx.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        brandx['site'] = 'source10'\n",
    "        source10sales = pd.DataFrame(brandx, columns=salesheader)\n",
    "        dscosales = dscosales.append(source10sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print('There is no source10 Order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d21a2a81-dc13-4710-9ec1-5c0a6eddada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE10 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12185b46-9c53-43e5-b2e8-46756036b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f377cc4-6abf-4f04-8454-f7dd09efd840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no source11 Order\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = f'{linknr}'\n",
    "params = {'ordersCreatedSince': {weekago}, 'until': {Current_Date} }\n",
    "headers = {\"Authorization\": \"Bearer \" + tokenlt, \"Content-Type\":\"application/json\", \"Accept\":\"application/json\" }\n",
    "auth_response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "orders = json.loads(auth_response.text)\n",
    "df3 = pd.json_normalize(orders, 'orders')\n",
    "if orders:\n",
    "    try:\n",
    "        df3['dscoCreateDate'] = pd.to_datetime(df3['dscoCreateDate'], errors='coerce')\n",
    "        df3['datetofilter'] = df3['dscoCreateDate'].dt.tz_convert('US/Eastern')\n",
    "        df3['datetofilter'] = df3['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        df3 = df3[(df3['datetofilter'] > weekago) & (df3['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['lineItems']\n",
    "        dt = df3[FIELDS]\n",
    "        dt = dt.explode('lineItems')\n",
    "        df_final = (pd.DataFrame(dt['lineItems'].apply(pd.Series)))\n",
    "        source11 = df_final[['sku', 'quantity']]\n",
    "        source11 = source11.rename({'sku' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source11['site'] = 'source11'\n",
    "        source11sales = pd.DataFrame(source11, columns=salesheader)\n",
    "        dscosales = dscosales.append(source11sales, ignore_index=True)\n",
    "        \n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "        print('There is no source11 Order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbaa78d3-ba97-453b-b5f6-5b7614a38e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE11 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4cf1fdd-3ac9-475d-ae72-15b5fdaea184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd9412aa-b29e-43c4-a273-7ec135713259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = f'{linkw}'\n",
    "\n",
    "payload = {\n",
    "  \"grant_type\":\"client_credentials\",\n",
    "  \"client_id\": keywa,\n",
    "  \"client_secret\": secretwa,\n",
    "  \"audience\": audience\n",
    "}\n",
    "\n",
    "result = json.dumps(payload)\n",
    "\n",
    "headers = {\n",
    "    'content-type': \"application/json\",\n",
    "    'cache-control': \"no-cache\",\n",
    "}\n",
    "response = requests.request(\"POST\", url, data=result, headers=headers)\n",
    "source12response = json.loads(response.text)\n",
    "source12response = pd.json_normalize(source12response)\n",
    "softoken = source12response['access_token'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff96d2d5-4e90-4886-a52c-4f2b5b6d4ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\AppData\\Local\\Temp\\ipykernel_1924\\4022858641.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  source13sold = source13sold.append(source13sales, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Authorization\": \"Bearer \" + softoken}\n",
    "\n",
    "query = 'query getDropshipPurchaseOrders {getDropshipPurchaseOrders (limit: 1000, hasResponse: false, fromDate: \"2023-01-01T00:01:00.000-05:00\") {poNumber,poDate,orderId,estimatedShipDate,customerName,customerAddress1,customerAddress2,customerCity,customerState,customerPostalCode,customerEmail,orderType,shippingInfo {shipSpeed,carrierCode},packingSlipUrl,warehouse {id,name,address {name,address1,address2,address3,city,state,country,postalCode}},products {partNumber,quantity,price,event {id,type,name,startDate,endDate}},shipTo {name,address1,address2,address3,city,state,country,postalCode,phoneNumber}}}'\n",
    "\n",
    "def run_query(query):\n",
    "    request = requests.post(url=linkgra, json={'query': query}, headers=headers)\n",
    "    if request.status_code == 200:\n",
    "        return request.json()\n",
    "    else:\n",
    "        raise Exception(\"Query failed to run by returning code of {}. {}\".format(request.status_code, query))\n",
    "\n",
    "result = run_query(query)\n",
    "dfway = pd.json_normalize(result['data']['getDropshipPurchaseOrders'])\n",
    "\n",
    "if result:\n",
    "    try:\n",
    "        dfway['poDate'] = pd.to_datetime(dfway['poDate'], errors='coerce')\n",
    "        dfway['datetofilter'] = dfway['poDate'].dt.tz_convert('US/Eastern')\n",
    "        dfway['datetofilter'] = dfway['datetofilter'].dt.strftime(\"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        source13 = dfway[(dfway['datetofilter'] > weekago) & (dfway['datetofilter'] < filterbydate)]\n",
    "        FIELDS = ['products']\n",
    "        dt = source13[FIELDS]\n",
    "        dt = dt.explode('products')\n",
    "        source13final = (pd.DataFrame(dt['products'].apply(pd.Series)))\n",
    "        source13 = source13final[['partNumber', 'quantity']]\n",
    "        source13 = source13.rename({'partNumber' : 'sku', 'quantity': 'qty'}, axis=1)\n",
    "        source13['site'] = 'source13'\n",
    "        source13sales = pd.DataFrame(source13, columns=salesheader)\n",
    "        source13sold = source13sold.append(source13sales, ignore_index=True)\n",
    "    except (KeyError, IndexError, TypeError, NameError):\n",
    "         print(\"There is no source13 Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fec83c35-3534-43d7-8ef2-ff9f24d5f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE13 ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d380c913-753c-40e7-ab58-82eeeeba8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(pathfolders + 'projectb/keys.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "313606c8-cf2b-4966-a551-1cbaa56e8636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n"
     ]
    }
   ],
   "source": [
    "source14path = data['paths']['source14']\n",
    "PATH = source14path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source14 = pd.read_excel(PATH)\n",
    "    source14 = source14[['Supplier Code', 'QTY', 'RequestorName']]\n",
    "    source14 = source14.rename({'Supplier Code' : 'sku', 'QTY': 'qty', 'RequestorName': 'site'}, axis=1)\n",
    "    source14['site'] = 'source14'\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source14 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source14']}\n",
    "    source14 = pd.DataFrame(source14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aba64d49-579d-40aa-9256-21a441b73547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n"
     ]
    }
   ],
   "source": [
    "source15path = data['paths']['source15']\n",
    "PATH = source15path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source15 = pd.read_excel(PATH)\n",
    "    source15 = source15[['Vendor SKU', 'Quantity']]\n",
    "    source15['site'] = 'source15'\n",
    "    source15 = source15.rename({'Vendor SKU' : 'sku', 'Quantity': 'qty'}, axis=1)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source15 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source15']}\n",
    "    source15 = pd.DataFrame(source15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51fe578c-20fb-4974-b63b-29824546a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the file is missing or not readable\n"
     ]
    }
   ],
   "source": [
    "source16path = data['paths']['source16']\n",
    "PATH = source16path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source16 = pd.read_csv(PATH)\n",
    "    source16 = source16[['Sku', 'Quantity']]\n",
    "    source16['site'] = 'source16'\n",
    "    source16 = source16.rename({'Sku' : 'sku', 'Quantity': 'qty'}, axis=1)\n",
    "    source16.dropna(how='any', inplace=True)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source16 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source16']}\n",
    "    source16 = pd.DataFrame(source16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5f897dc-d3e5-435b-bc0b-6d24e2ab6ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n"
     ]
    }
   ],
   "source": [
    "source17path = data['paths']['source17']\n",
    "PATH = source17path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source17 = pd.read_csv(PATH, sep=\"\\t\")\n",
    "    source17 = source17[['sku', 'quantity-purchased']]\n",
    "    source17['site'] = 'source17'\n",
    "    source17 = source17.rename({'quantity-purchased' : 'qty'}, axis=1)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source17 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source17']}\n",
    "    source17 = pd.DataFrame(source17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8fcbaee-db18-432e-a561-10f80b61dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enchante\\anaconda3\\envs\\pybuild\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "source18path = data['paths']['source18']\n",
    "PATH = source18path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source18 = pd.read_excel(PATH)\n",
    "    source18 = source18[['SKU', 'Qty']]\n",
    "    source18['site'] = 'source18'\n",
    "    source18 = source18.rename({'SKU' : 'sku', 'Qty': 'qty'}, axis=1)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source18 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source18']}\n",
    "    source18 = pd.DataFrame(source18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c88463d-cc58-4e18-88fd-e8419af20f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n"
     ]
    }
   ],
   "source": [
    "source20path = data['paths']['source20']\n",
    "path = source20path\n",
    "dir = os.listdir(path)\n",
    "if len(dir) != 0:\n",
    "    print(\"OKAY\")\n",
    "    os.chdir(path)\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "    source20 = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    source20 = source20[['Item SKU', 'Qty']]\n",
    "    source20['site'] = 'source20'\n",
    "    source20 = source20.rename({'Item SKU' : 'sku', 'Qty': 'qty'}, axis=1)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source20 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source20']}\n",
    "    source20 = pd.DataFrame(source20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc34fc31-d6f0-44eb-ae16-22f4f0657b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the file is missing or not readable\n"
     ]
    }
   ],
   "source": [
    "source21path = data['paths']['source21']\n",
    "path = source20path\n",
    "if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "    print(\"OKAY\")\n",
    "    source21 = pd.read_csv(PATH)\n",
    "    source21 = faire[['SKU', 'Quantity']]\n",
    "    source21['site'] = 'source21'\n",
    "    source21 = source21.rename({'SKU' : 'sku', 'Quantity': 'qty'}, axis=1)\n",
    "else:\n",
    "    print(\"Either the file is missing or not readable\")\n",
    "    logger.debug(\"Dsco file does not exist\")\n",
    "    source21 = {\"sku\": ['other'], \"qty\": [0], \"site\": ['source21']}\n",
    "    source21 = pd.DataFrame(source21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d9b72de-76ea-4673-832e-13bb20a9b49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales = pd.concat([dscosales,source13sold,source3sold,source4sold,source5sold,source6sold,source2reqsold,source1sold,source14,source15,source16,source17,source18,source20,source21], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e801c17-5805-4a9d-ac27-8ad1c9978cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 0 value nan sales\n",
    "sales = sales[sales[\"sku\"].str.contains(\"sku\") == False]\n",
    "sales = sales[sales[\"sku\"].str.contains(\"Item SKU\") == False]\n",
    "sales = sales[sales[\"sku\"].str.contains(\"other\") == False]\n",
    "sales = sales.apply(lambda x: x.astype(str).str.lower())\n",
    "sales['sku'] = sales['sku'].astype('string') \n",
    "sales['sku'] = sales['sku'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "395aff71-cdbd-4659-84e7-2b9e80492d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLD UNIQUE VALUE\n",
    "qtycount = sales[[\"sku\", \"qty\"]]\n",
    "qtycount = qtycount[qtycount[\"sku\"].str.contains(\"sku\") == False]\n",
    "qtycount.set_index('sku')\n",
    "qtycount['qty'] = qtycount['qty'].astype(float)\n",
    "qtychanged = qtycount.sort_values(by='sku')\n",
    "soldvalue = qtychanged.groupby([\"sku\"]).qty.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46c0e130-b95f-4052-bf99-eec871cf512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Mysql Database \n",
    "database_username = 'root'\n",
    "database_password = localdb\n",
    "database_ip       = '127.0.0.1'\n",
    "database_name     = 'sales'\n",
    "auth_plugin = 'mysql_native_password'\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name, auth_plugin))\n",
    "# Local Mysql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49a46176-f489-4dba-8498-ea0d06ebefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOCK CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4a684d6-2a1c-42f3-ba93-d859d45e4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "allskus = {'sku':['sku1blueq', 'sku1green', 'sku1orange', 'sku1pinkk', 'sku1green', 'sku1orangee', 'sku1ppink', 'sku2anth16pcs', 'sku2anth16pcs', 'sku2anthbth', 'sku2anthbth4'#......]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b834566-b08e-4fba-a04c-110ad70ec803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soldvalue = soldvalue.set_index('sku')\n",
    "allskus = {'sku':['sku1blueq', 'sku1green', 'sku1orange', 'sku1pinkk', 'sku1green', 'sku1orangee', 'sku1ppink', 'sku2anth16pcs', 'sku2anth16pcs', 'sku2anthbth', 'sku2anthbth4'#......]}\n",
    "allskus = pd.DataFrame(allskus)\n",
    "allskus[\"qty\"] = 0\n",
    "allskus = allskus.set_index('sku')\n",
    "allskus.update(soldvalue)\n",
    "soldbysites = allskus.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26fcf769-d9c2-41bc-ae7a-b8a9a4e9e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sold = soldbysites.set_index('sku').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "539a9252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#That's where the set(RETAIL) SKUs converted to wholesale SKUs\n",
    "sku1blue = (sold.sku1blueq * 1) \n",
    "sku1gree = (sold.sku1green * 1) + (sold.sku1green * 1) + (sold.skugreen * 1)\n",
    "sku1oran = (sold.sku1orange * 1) + (sold.sku1orangee * 1) + (sold.sku1orannge * 1)\n",
    "sku1pink = (sold.sku1pinkk * 1) + (sold.sku1ppink * 1)\n",
    "##EXAMPLE OF SET SKU IS BELOW\n",
    "sku2anthb = (sold.sku2anth16pcs * 4) + (sold.sku2anth16pcs * 2) + (sold.sku2anthbth * 2) + (sold.sku2anthbth4 * 4)\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d3fa4ec-73a8-4073-8dde-be001960089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING WHOLESALE SKU TO SOLD QTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69ce35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku = [\"sku1blue\", \"sku1gree\", \"sku1oran\", \"sku1pink\", \"sku2anthb\", #...,...,...]\n",
    "qty = [sku1blue, sku1gree, sku1oran, sku1pink, sku2anthb,#...,...,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e1c629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'sku': sku, 'qty': qty}\n",
    "soldfullist = pd.DataFrame(dict)\n",
    "soldqty = soldfullist[soldfullist.qty != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6166676c-12de-4e67-831e-c5693eb46a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockathand = pd.read_csv(pathfolders + 'cloudbbeh/stockfiles/newstock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51ee450a-e7d4-4797-a2d9-416b5fe8f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstock1 = stockathand[\"qty\"].subtract(soldfullist[\"qty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "487ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "whlesku = [sku1blue, sku1gree, sku1oran, sku1pink, sku2anthb,#...,...,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "932a6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = { 'sku': whlesku, 'qty': newstock1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8cc6b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstock = pd.DataFrame(dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f7010cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstock.to_csv(pathfolders + \"cloudbbeh/stockfiles/newstock.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa1b7cc7-e5ec-497e-8e3a-bb71ae166b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole = newstock.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "734758c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign category for reporting purpose\n",
    "nebu = [\"beach\", \"beach\", \"hand towel\", \"beach\", \"bath towel\"#...,...,...]\n",
    "whole['subcategory'] = nebu\n",
    "#Assign colors for reporting purpose\n",
    "color = [\"blue\", \"green\", \"orange\", \"pink\", \"anthracite\"#...,...,...]\n",
    "whole['color'] = color\n",
    "#Assing brand for reporting purpose\n",
    "brand = [\"BRAND1\", \"BRAND1\", \"BRAND1\", \"BRAND1\", \"BRAND2\"#...,...,...]\n",
    "whole['brand'] = brand\n",
    "\n",
    "whole2 = whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "05f2bbc2-5692-493e-9d05-66ff0bf2488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b825fe0d-f802-46ad-a0e8-49fe6a841d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of stock calculation by category condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f72b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = whole[whole['qty'] < 100]\n",
    "handstock = whole2.loc[(whole2['qty'] < 100) & (whole2['subcategory'].str.startswith('hand'))]\n",
    "washstock = whole2.loc[(whole2['qty'] < 100) & (whole2['subcategory'].str.startswith('wash'))]\n",
    "bathstock = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('bath towel'))]\n",
    "beach = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('beach'))]\n",
    "bathsheet = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('bath sheet'))]\n",
    "bathrobe = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('bathrobe'))]\n",
    "bathmath = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('bath math'))]\n",
    "showercurtain = whole2.loc[(whole2['qty'] < 50) & (whole2['subcategory'].str.startswith('shower curtain'))]\n",
    "merged_df = pd.concat([handstock, washstock, bathstock, beach, bathsheet, bathrobe, bathmath, showercurtain])\n",
    "dflist = pd.DataFrame(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6550dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist.to_csv(pathfolders + \"cloudbbeh/stockfiles/outofstock.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60ca93a3-a9e2-4e72-aa7d-67de89b7fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of stock calculation by category condition END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "598e5c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole2.to_csv(pathfolders + 'cloudbbeh/stock/data/newstock.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45156cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole2.to_csv(pathfolders + 'cloudbbeh/gonder/newstock.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50d5aaed-845a-4be7-9b8d-0a033e513670",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole2['date'] = date\n",
    "whole2['date'] = pd.to_datetime(whole2['date'])\n",
    "whole2['Year'] = whole2['date'].dt.year\n",
    "whole2['Month'] = whole2['date'].dt.month_name()\n",
    "whole2.set_index('sku', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81d483b4-f4f3-4d47-a17a-2f732e696d55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INVENTORY DATA TO SQL WITH DATE\n",
    "whole2.to_sql(con=database_connection, name='inventory', if_exists='append')\n",
    "#INVENTORY DATA TO SQL WITH DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4575ae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign price for reporting purpose\n",
    "sales.loc[(sales.sku==\"sku1blueq\"),'cost']='50.25'\n",
    "sales.loc[(sales.sku==\"sku1green\"),'cost']='50.25'\n",
    "sales.loc[(sales.sku==\"sku1orange\"),'cost']='50.25'\n",
    "sales.loc[(sales.sku==\"sku2anth16pcs\"),'cost']='50.25'\n",
    "sales.loc[(sales.sku==\"sku2anth6pcs\"),'cost']='50.25'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "174f040f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign category for reporting purpose\n",
    "sales.loc[(sales.sku==\"sku1blueq\"),'category']='towel'\n",
    "sales.loc[(sales.sku==\"sku1green\"),'category']='towel'\n",
    "sales.loc[(sales.sku==\"sku1orange\"),'category']='towel'\n",
    "sales.loc[(sales.sku==\"sku2anth16pcs\"),'category']='towel'\n",
    "sales.loc[(sales.sku==\"sku2anth6pcs\"),'category']='towel'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7aa7d1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign subcategory for reporting purpose\n",
    "sales.loc[(sales.sku==\"sku1blueq\"),'subcategory']='beach towel'\n",
    "sales.loc[(sales.sku==\"sku1green\"),'subcategory']='beach towel'\n",
    "sales.loc[(sales.sku==\"sku1orange\"),'subcategory']='hand towel'\n",
    "sales.loc[(sales.sku==\"sku2anth16pcs\"),'subcategory']='beach towel'\n",
    "sales.loc[(sales.sku==\"sku2anth6pcs\"),'subcategory']='bath towel'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ff07145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign brand for reporting purpose\n",
    "sales.loc[(sales.sku==\"sku1blueq\"),'brand']='BRAND1'\n",
    "sales.loc[(sales.sku==\"sku1green\"),'brand']='BRAND1'\n",
    "sales.loc[(sales.sku==\"sku1orange\"),'brand']='BRAND1'\n",
    "sales.loc[(sales.sku==\"sku2anth16pcs\"),'brand']='BRAND2'\n",
    "sales.loc[(sales.sku==\"sku2anth6pcs\"),'brand']='BRAND2'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cf6b35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "33ce2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['date'] = pd.to_datetime(sales['date'])\n",
    "sales['Year'] = sales['date'].dt.year\n",
    "sales['Month'] = sales['date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5956b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.qty = sales.qty.astype(float)\n",
    "sales.cost = sales.cost.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "91cef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['date'] = pd.to_datetime(sales['date'], format='%Y-%m-%d')\n",
    "sales[\"total\"] = sales[\"qty\"] * sales[\"cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7f347a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand1 = sales.loc[sales['brand'] == 'BRAND1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a041245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand2 = sales.loc[sales['brand'] == 'BRAND2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f28ea8e-8dcb-4835-bd7d-efa283841b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesall = [brand1, brand2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a2c4c71f-ac72-4e4c-945e-0f99fa32b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesall = pd.concat(salesall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "231e8a93-b252-4ca4-934c-d25b1d6bc59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesall.set_index('sku', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e7a6841-8ad2-498f-8dca-e46ddf7f19fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MySQL APPEND // ALLSALES\n",
    "salesall.to_sql(con=database_connection, name='allsales', if_exists='append')\n",
    "#MySQL APPEND END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2bbff6ce-7302-48ad-accb-99477930bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCLOUD APPEND // ALLSALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "354ea17d-03a7-4f99-a272-02d41484ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46340 rows and 11 columns to portfolio-367918.weeklysales.allsales\n"
     ]
    }
   ],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = pathfolders + 'projectb/portfolio-367918-fa99ce9f63c4.json'\n",
    "client = bigquery.Client()\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "\n",
    "    schema = [\n",
    "          bigquery.SchemaField(\"sku\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"qty\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "          bigquery.SchemaField(\"site\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"cost\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "          bigquery.SchemaField(\"category\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"subcategory\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"brand\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"date\", bigquery.enums.SqlTypeNames.DATE),\n",
    "          bigquery.SchemaField(\"Year\", bigquery.enums.SqlTypeNames.INTEGER),\n",
    "          bigquery.SchemaField(\"Month\", bigquery.enums.SqlTypeNames.STRING),\n",
    "          bigquery.SchemaField(\"total\", bigquery.enums.SqlTypeNames.FLOAT)\n",
    "    ],\n",
    "    \n",
    "    write_disposition=\"WRITE_APPEND\",\n",
    ")\n",
    "dataset_ref = client.dataset('weeklysales', project = 'portfolio-367918')\n",
    "table_ref = dataset_ref.table('allsales')  \n",
    "job = client.load_table_from_dataframe(brand1, table_ref, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "table = client.get_table(table_ref)\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_ref\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e43cef2a-433e-4d7d-9446-29a152f1cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCLOUD APPEND // ALLSALES END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa048707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Name the file with todays date and write inside sold file\n",
    "path = pathfolders + 'cloudbbeh/eh/2023/data'\n",
    "output_file = os.path.join(path, excelfilename)\n",
    "brand1.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e60781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name the file with todays date and write inside sold file\n",
    "path = pathfolders + 'cloudbbeh/bb/2023/data'\n",
    "output_file = os.path.join(path, excelfilename)\n",
    "brand2.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d82c340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfilenameeh = date +'-brand1' + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54ed6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gonderilecek Order file \n",
    "brand1file = brand1.groupby(['sku','cost'])['qty'].sum().reset_index()\n",
    "brand1file['total'] = brand1file['cost'] * brand1file['qty']\n",
    "path = pathfolders + 'cloudbbeh/gonder'\n",
    "output_file = os.path.join(path, excelfilenameeh)\n",
    "brand1file.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0bcacb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gonderilecek Order file \n",
    "brand2file = brand2.groupby(['sku','cost'])['qty'].sum().reset_index()\n",
    "excelfilenamebb = date +'-brand2' + \".csv\"\n",
    "brand2file['total'] = brand2file['cost'] * brand2file['qty']\n",
    "path = pathfolders + 'cloudbbeh/gonder'\n",
    "output_file = os.path.join(path, excelfilenamebb)\n",
    "brand2file.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a1527ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().date()\n",
    "today = str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2d4e4-f4c1-4dcd-9e10-9cbb917cf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHOLESALE SKU PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e3fcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholecat = soldfullist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d583b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign category for reporting purpose\n",
    "wholecat.loc[(wholecat.sku=='sku1blue'),'category']='towel'\n",
    "wholecat.loc[(wholecat.sku=='sku1gree'),'category']='towel'\n",
    "wholecat.loc[(wholecat.sku=='sku1oran'),'category']='towel'\n",
    "wholecat.loc[(wholecat.sku=='sku1pink'),'category']='towel'\n",
    "wholecat.loc[(wholecat.sku=='sku2anthb'),'category']='towel'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43935ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholecat['date'] = date\n",
    "wholecat['date'] = pd.to_datetime(wholecat['date'])\n",
    "wholecat['Year'] = wholecat['date'].dt.year\n",
    "wholecat['Month'] = wholecat['date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ff4928a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assign brand for reporting purpose\n",
    "wholecat.loc[(wholecat.sku=='sku1blue'),'brand']='BRAND1'\n",
    "wholecat.loc[(wholecat.sku=='sku1gree'),'brand']='BRAND1'\n",
    "wholecat.loc[(wholecat.sku=='sku1oran'),'brand']='BRAND1'\n",
    "wholecat.loc[(wholecat.sku=='sku1pink'),'brand']='BRAND1'\n",
    "wholecat.loc[(wholecat.sku=='sku2anthb'),'brand']='BRAND2'\n",
    "#.......\n",
    "#........\n",
    "#........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ace5e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand1 = wholecat.loc[wholecat['brand'] == 'BRAND1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95fa1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand2 = wholecat.loc[wholecat['brand'] == 'BRAND2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "31332093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR WHOLESALE SKUS\n",
    "#Name the file with todays date and write inside sold file\n",
    "path = pathfolders + 'cloudbbeh/bb/2023/data/wholesale'\n",
    "output_file = os.path.join(path, excelfilename)\n",
    "brand2.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19d7c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR WHOLESALE SKUS\n",
    "#Name the file with todays date and write inside sold file\n",
    "path = pathfolders + 'cloudbbeh/eh/2023/data/wholesale'\n",
    "output_file = os.path.join(path, excelfilename)\n",
    "brand1.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f713131-03fa-48b7-a7cc-023f38c69f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholesaleqtysold = pd.concat([brand1, brand2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "41535312-8c25-493e-a413-318cd483eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholesaleqtysold.set_index('sku', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5f5eccce-fbfc-40fa-8007-be7c9fc59763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLD WHOLESALE SKU DATA TO SQL WITH DATE\n",
    "wholesaleqtysold.to_sql(con=database_connection, name='qtysold', if_exists='append')\n",
    "#SOLD WHOLESALE SKU DATA TO SQL WITH DATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
